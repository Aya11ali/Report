{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7fpNLzW8KVj7c+tzNblr2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98xcGiKcxKd2","executionInfo":{"status":"ok","timestamp":1764153236489,"user_tz":-120,"elapsed":8956,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}},"outputId":"8b6aa60f-e73c-4e47-c8cd-9b20cda2a0f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","\n","project_path = \"/content/drive/MyDrive/Colab Notebooks/report\"\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/report/data\"\n","module_path = \"/content/drive/MyDrive/Colab Notebooks/report/modules\"\n","utils_path = \"/content/drive/MyDrive/Colab Notebooks/report/utils\"\n","tests_path = \"/content/drive/MyDrive/Colab Notebooks/report/tests\""]},{"cell_type":"code","source":["%%writefile \"{project_path}/config/config.json\"\n","{\n","    \"OPENAI_API_KEY\": \"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\",\n","    \"MODEL_NAME\": \"x-ai/grok-4.1-fast\"\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRxPnd4BBjj1","executionInfo":{"status":"ok","timestamp":1764153237249,"user_tz":-120,"elapsed":730,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}},"outputId":"9e540edc-328f-46c6-8691-7940ee203f82"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/Colab Notebooks/report/config/config.json\n"]}]},{"cell_type":"code","source":["%%writefile \"{utils_path}/overview_generator.py\"\n","import json\n","\n","class OverviewGenerator:\n","    \"\"\"\n","    Responsible for:\n","    - Preparing the Overview prompt\n","    - Calling LLMClient to get the Overview text\n","    \"\"\"\n","\n","    def __init__(self, llm_client):\n","        self.llm_client = llm_client\n","\n","        self.system_prompt = \"\"\"\n","        You are a data analyst assistant.\n","        You are given a dataset profile in JSON format, which includes:\n","        - metadata: general info (rows, columns, missing values)\n","        - schema: column-level info (name, type, unique values, sample values)\n","        - sample_rows: few example rows\n","        - statistics: numeric/categorical summaries\n","\n","        Your task:\n","        1. Generate a short, clear overview (3-5 sentences) describing the dataset.\n","        2. Focus on the meaning and context: what the dataset represents, what the entities/records are.\n","        3. Include only the most important insights.\n","        4. Mention missing values or imbalanced target if relevant.\n","        5. Format: a short paragraph + a bullet list of key insights.\n","        6. Return ONLY the formatted text.\n","        \"\"\"\n","\n","    def generate(self, dataset_profile: dict) -> str:\n","        \"\"\"\n","        Takes the full dataset profile dict and returns\n","        the LLM-generated overview text.\n","        \"\"\"\n","\n","        user_prompt = f\"Dataset profile:\\n{json.dumps(dataset_profile, separators=(',', ':'))}\"\n","\n","        return self.llm_client.chat(\n","            system_prompt=self.system_prompt,\n","            user_prompt=user_prompt,\n","            temperature=0\n","        )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yr3IhdtrDhtv","executionInfo":{"status":"ok","timestamp":1764153237299,"user_tz":-120,"elapsed":48,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}},"outputId":"d12af893-563e-493a-8a3c-bab71df7491c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/Colab Notebooks/report/utils/overview_generator.py\n"]}]},{"cell_type":"code","source":["%%writefile \"{utils_path}/data_health_base.py\"\n","from abc import ABC, abstractmethod\n","\n","class BaseHealthCheck(ABC):\n","    \"\"\"Abstract class for all data health checks.\"\"\"\n","\n","    @abstractmethod\n","    def run(self, df) -> \"HealthCheckResult\":\n","        \"\"\"Run the health check and return a HealthCheckResult.\"\"\"\n","        raise NotImplementedError\n","\n","\n","class HealthCheckResult:\n","    \"\"\"Holds the output of a health check.\"\"\"\n","\n","    def __init__(self, name: str, status: str, details: dict):\n","        self.name = name\n","        self.status = status  # 'healthy' | 'warning' | 'critical'\n","        self.details = details\n","\n","    def __repr__(self):\n","        return f\"{self.name} ({self.status}) -> {self.details}\"\n","\n","\n","class HealthReport:\n","    \"\"\"Collect results from multiple health checks.\"\"\"\n","\n","    def __init__(self):\n","        self.results = []\n","\n","    def add(self, result: HealthCheckResult):\n","        self.results.append(result)\n","\n","    def to_dict(self):\n","        return {\n","            \"checks\": [\n","                {\"name\": r.name, \"status\": r.status, \"details\": r.details}\n","                for r in self.results\n","            ]\n","        }\n","\n","    def __repr__(self):\n","        return \"\\n\".join([repr(r) for r in self.results])\n","\n","\n","class HealthValidator:\n","    \"\"\"Coordinator to run multiple health checks.\"\"\"\n","\n","    def __init__(self, checks: list):\n","        self.checks = checks\n","\n","    def run(self, df) -> HealthReport:\n","        report = HealthReport()\n","        for check in self.checks:\n","            result = check.run(df)\n","            report.add(result)\n","        return report"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7oWtfY0gQuS","executionInfo":{"status":"ok","timestamp":1764153237521,"user_tz":-120,"elapsed":219,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}},"outputId":"140c88a2-816a-4938-a087-cdd40f2dfb2a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/Colab Notebooks/report/utils/data_health_base.py\n"]}]},{"cell_type":"code","source":["%%writefile \"{utils_path}/checks.py\"\n","from utils.data_health_base import BaseHealthCheck, HealthCheckResult\n","import pandas as pd\n","\n","class EmptyDatasetCheck(BaseHealthCheck):\n","    \"\"\"\n","    Checks whether the dataset is empty:\n","    - No rows\n","    - OR zero columns\n","    \"\"\"\n","\n","    def run(self, df: pd.DataFrame) -> HealthCheckResult:\n","\n","        is_empty = df.empty\n","        row_count = len(df)\n","        column_count = len(df.columns)\n","\n","        if is_empty:\n","            status = \"critical\"\n","            message = \"Dataset is completely empty. No analysis can be performed.\"\n","        elif row_count == 0:\n","            status = \"critical\"\n","            message = \"Dataset has columns but contains zero rows.\"\n","        else:\n","            status = \"healthy\"\n","            message = \"Dataset has valid rows and columns.\"\n","\n","        return HealthCheckResult(\n","            name=\"Empty Dataset Check\",\n","            status=status,\n","            details={\n","                \"row_count\": row_count,\n","                \"column_count\": column_count,\n","                \"is_empty\": is_empty,\n","                \"message\": message\n","            }\n","        )\n","\n","class NullRatioCheck(BaseHealthCheck):\n","    \"\"\"Calculates the null percentage for each column.\"\"\"\n","\n","    def __init__(self, warning_threshold=0.2, critical_threshold=0.5):\n","        self.warning_threshold = warning_threshold\n","        self.critical_threshold = critical_threshold\n","\n","    def run(self, df) -> HealthCheckResult:\n","        null_ratios = df.isna().mean().to_dict()\n","        max_null = max(null_ratios.values()) if null_ratios else 0\n","\n","        if max_null >= self.critical_threshold:\n","            status = \"critical\"\n","        elif max_null >= self.warning_threshold:\n","            status = \"warning\"\n","        else:\n","            status = \"healthy\"\n","\n","        return HealthCheckResult(\n","            name=\"Null Ratio Check\",\n","            status=status,\n","            details={\n","                \"null_ratio_per_column\": null_ratios,\n","                \"warning_threshold\": self.warning_threshold,\n","                \"critical_threshold\": self.critical_threshold\n","            }\n","        )\n","\n","class DuplicateRowsCheck(BaseHealthCheck):\n","    \"\"\"\n","    Detects duplicate rows in the dataset.\n","    Returns:\n","        - duplicate_count\n","        - duplicate_percentage\n","        - sample_duplicates (first 5 duplicate rows)\n","    \"\"\"\n","\n","    def __init__(self, warning_threshold=0.05, critical_threshold=0.2):\n","        self.warning_threshold = warning_threshold\n","        self.critical_threshold = critical_threshold\n","\n","    def run(self, df: pd.DataFrame) -> HealthCheckResult:\n","\n","        duplicate_mask = df.duplicated()\n","        duplicate_count = int(duplicate_mask.sum())\n","        duplicate_percentage = float(duplicate_count / len(df)) if len(df) > 0 else 0\n","\n","        # status decision\n","        if duplicate_percentage >= self.critical_threshold:\n","            status = \"critical\"\n","        elif duplicate_percentage >= self.warning_threshold:\n","            status = \"warning\"\n","        else:\n","            status = \"healthy\"\n","\n","        # get small sample of duplicate rows\n","        sample_duplicates = df[duplicate_mask].head().to_dict(orient=\"records\")\n","\n","        return HealthCheckResult(\n","            name=\"Duplicate Rows Check\",\n","            status=status,\n","            details={\n","                \"duplicate_count\": duplicate_count,\n","                \"duplicate_percentage\": round(duplicate_percentage, 4),\n","                \"warning_threshold\": self.warning_threshold,\n","                \"critical_threshold\": self.critical_threshold,\n","                \"sample_duplicates\": sample_duplicates\n","            }\n","        )\n","\n","class OutlierIQRCheck(BaseHealthCheck):\n","    \"\"\"\n","    Detects outliers in numeric columns using the IQR method.\n","    \"\"\"\n","\n","    def __init__(self, warning_threshold=0.05, critical_threshold=0.1, sample_size=5):\n","\n","        self.warning_threshold = warning_threshold\n","        self.critical_threshold = critical_threshold\n","        self.sample_size = sample_size\n","\n","    def run(self, df: pd.DataFrame) -> HealthCheckResult:\n","        numeric_cols = df.select_dtypes(include='number').columns\n","        numeric_cols = [c for c in numeric_cols if df[c].nunique() > 2]  # فقط الأعمدة المتنوعة\n","        outlier_counts = {}\n","        outlier_samples = {}\n","\n","        for col in numeric_cols:\n","            q1, q3 = df[col].quantile([0.25, 0.75])\n","            iqr = q3 - q1\n","            lower, upper = q1 - 1.5*iqr, q3 + 1.5*iqr\n","            mask = (df[col] < lower) | (df[col] > upper)\n","            count = int(mask.sum())\n","            outlier_counts[col] = count\n","            outlier_samples[col] = df.loc[mask].head(self.sample_size).to_dict(orient='records')\n","\n","        max_outlier_pct = max((count/len(df) for count in outlier_counts.values()), default=0)\n","\n","        if max_outlier_pct >= self.critical_threshold:\n","            status = \"critical\"\n","        elif max_outlier_pct >= self.warning_threshold:\n","            status = \"warning\"\n","        else:\n","            status = \"healthy\"\n","\n","        return HealthCheckResult(\n","            name=\"Outlier IQR Check\",\n","            status=status,\n","            details={\n","                \"outlier_count_per_column\": outlier_counts,\n","                # \"outlier_samples_per_column\": outlier_samples,\n","                \"warning_threshold\": self.warning_threshold,\n","                \"critical_threshold\": self.critical_threshold\n","            }\n","        )"],"metadata":{"id":"EdP-9aAbx3qf","executionInfo":{"status":"ok","timestamp":1764155735954,"user_tz":-120,"elapsed":78,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dcd8fbcf-2b7d-49de-9906-86a7569678d8"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/Colab Notebooks/report/utils/checks.py\n"]}]},{"cell_type":"code","source":["%%writefile \"{utils_path}/data_health_generator.py\"\n","import json\n","\n","class DataHealthGenerator:\n","    \"\"\"\n","    Responsible for:\n","    - Preparing the Data Health prompt\n","    - Calling LLMClient to generate the final report text\n","    \"\"\"\n","\n","    def __init__(self, llm_client):\n","        self.llm_client = llm_client\n","\n","        self.system_prompt = \"\"\"\n","        You are a senior data quality analyst.\n","\n","        You will receive a JSON object that contains:\n","        - A list of data quality checks\n","        - Each check includes:\n","          - name: the check name\n","          - status: \"healthy\" | \"warning\" | \"critical\"\n","          - details: metrics and detected issues\n","\n","        Your task:\n","        1. Analyze all checks and produce a clear, concise Data Quality Report.\n","        2. Keep the tone professional and factual.\n","        3. Highlight only the important issues (missing values, outliers, duplicates, inconsistent data types, empty dataset, rare categories…).\n","        4. Organize your answer in this format:\n","\n","        ### Overall Quality Status:\n","        - A short (1–2 sentence) summary of the dataset's health.\n","\n","        ### Key Issues:\n","        - Bullet points describing detected problems (from all checks).\n","        - Each point should explain:\n","          - what the issue is\n","          - where it occurs (columns)\n","          - why it matters\n","\n","        ### Recommended Fixes:\n","        - For each issue category,\n","          give 1–2 practical suggestions for how to fix it.\n","\n","        Output Format:\n","        - Clean markdown text only.\n","        - Do NOT generate JSON.\n","        - Do NOT invent issues not present in the input.\n","        \"\"\"\n","\n","    def generate(self, health_report: dict) -> str:\n","        \"\"\"\n","        Takes the health report dict and returns\n","        LLM-generated data quality analysis.\n","        \"\"\"\n","\n","        user_prompt = (\n","            \"Data Quality Checks JSON:\\n\"\n","            f\"{json.dumps(health_report, separators=(',', ':'))}\"\n","        )\n","\n","        return self.llm_client.chat(\n","            system_prompt=self.system_prompt,\n","            user_prompt=user_prompt,\n","            temperature=0\n","        )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZFIeOC30IuK","executionInfo":{"status":"ok","timestamp":1764155406265,"user_tz":-120,"elapsed":57,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}},"outputId":"6df73d5a-1559-4881-a649-d2f8077d5f65"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing /content/drive/MyDrive/Colab Notebooks/report/utils/data_health_generator.py\n"]}]},{"cell_type":"code","source":["%%writefile \"{module_path}/data_health_module.py\"\n","from utils.checks import NullRatioCheck, OutlierIQRCheck, EmptyDatasetCheck, DuplicateRowsCheck\n","from utils.data_health_base import HealthValidator\n","\n","from utils.data_health_generator import DataHealthGenerator\n","from utils.llm_client import LLMClient\n","\n","class DataHealthModule:\n","    \"\"\"\n","    Responsible for generating the final Overview section.\n","    Handles:\n","    1. Building dataset profile\n","    2. Connecting with LLM via OverviewGenerator\n","    3. Returning the final overview text\n","    \"\"\"\n","\n","    def __init__(self, llm_client: LLMClient):\n","        self.null_ratio_check = NullRatioCheck()\n","        self.outlier_check = OutlierIQRCheck()\n","        self.empty_dataset_check = EmptyDatasetCheck()\n","        self.duplicate_rows_check = DuplicateRowsCheck()\n","        self.health_validator = HealthValidator([\n","            self.null_ratio_check,\n","            self.outlier_check,\n","            self.empty_dataset_check,\n","            self.duplicate_rows_check\n","        ])\n","        self.data_health_generator = DataHealthGenerator(llm_client=llm_client)\n","    def get_data_health(self, df) -> str:\n","      \"\"\"\n","      Main method to generate the Data Health section.\n","\n","      Steps:\n","      1. Run all health checks using HealthValidator\n","      2. Convert the report to dict\n","      3. Pass it to DataHealthGenerator\n","      4. Return the final generated text\n","      \"\"\"\n","\n","      health_report = self.health_validator.run(df)\n","\n","      health_dict = health_report.to_dict()\n","\n","      health_text = self.data_health_generator.generate(health_dict)\n","\n","      return health_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3q4Vm9MB0ZHI","executionInfo":{"status":"ok","timestamp":1764155462189,"user_tz":-120,"elapsed":14,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}},"outputId":"26e24169-0530-42ee-a8b7-7937baa758e4"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing /content/drive/MyDrive/Colab Notebooks/report/modules/data_health_module.py\n"]}]},{"cell_type":"code","source":["%%writefile \"{project_path}/main.py\"\n","import os\n","import sys\n","import pandas as pd\n","import json\n","\n","project_path = \"/content/drive/MyDrive/Colab Notebooks/report\"\n","sys.path.append(project_path)\n","\n","from utils.data_loader import CSVLoader\n","from utils.llm_client import LLMClient\n","from config.config import MODEL_NAME\n","from modules.overview_module import OverviewModule\n","from modules.data_health_module import DataHealthModule\n","\n","\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', None)\n","\n","def main():\n","  data_path = \"/content/drive/MyDrive/Colab Notebooks/report/data/Housing.csv\"\n","\n","\n","  loader = CSVLoader(data_path)\n","  df = loader.load()\n","\n","  llm_client = LLMClient(model=MODEL_NAME)\n","\n","  # overview_module = OverviewModule(llm_client=llm_client)\n","  # overview_text = overview_module.get_overview(df, file_path=data_path)\n","  # print(overview_text)\n","\n","  data_health_module = DataHealthModule(llm_client=llm_client)\n","  data_health_text = data_health_module.get_data_health(df)\n","  print(data_health_text)\n","\n","if __name__ == \"__main__\":\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRtAMjPS0FBJ","executionInfo":{"status":"ok","timestamp":1764155745762,"user_tz":-120,"elapsed":10,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}},"outputId":"a555a402-9b1c-4ad1-d331-23745a2c4516"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/Colab Notebooks/report/main.py\n"]}]},{"cell_type":"code","source":["!python3 \"{project_path}/main.py\""],"metadata":{"id":"UO-xnOJV0Vq0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764155756452,"user_tz":-120,"elapsed":9064,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}},"outputId":"0861c7e8-841e-48bf-ba7d-e202885e08f8"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["### Overall Quality Status:\n","The dataset is generally healthy with no missing values, duplicates, or empty data, but shows warnings due to outliers in several numerical columns.\n","\n","### Key Issues:\n","- **Outliers detected via IQR method**: Present in price (15 outliers), area (12), bedrooms (12), bathrooms (1), stories (41), and parking (12) columns; these represent notable portions of the 545 rows and can distort statistical summaries, model training, and predictive accuracy.\n","\n","### Recommended Fixes:\n","- **Outliers**:\n","  - Investigate outliers contextually (e.g., via domain knowledge or visualization) and consider removal, capping at IQR bounds, or transformation (e.g., log scaling) for skewed distributions.\n","  - Apply robust scaling methods like Winsorization to limit extreme values while retaining data volume.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DFcuYujgjks2","executionInfo":{"status":"ok","timestamp":1764153243542,"user_tz":-120,"elapsed":22,"user":{"displayName":"Aya Ali","userId":"05688978152922016817"}}},"execution_count":8,"outputs":[]}]}